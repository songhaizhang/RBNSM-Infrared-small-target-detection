###R-CNN, Fast R-CNN, Faster R-CNN
####R-CNN（区域卷积神经网络）
R-CNN在cnn的基础上加入了候选区域，对于候选区域的选取，有如下方法：
1. 滑窗法：对输入图像进行不同大小的滑窗，并且每次滑窗时，都使用训练好的分类器去判别框中是否有目标。
2. 选择性搜索（Selective Search）：利用图像分割算法

算法思想：
1. **候选区域生成：** 一张图片生成1k-2k个候选区域（选择性搜索）
2. **特征提取：** 对每个候选区域，使用深度卷积网络提取特征
3. **类别判断：** 特征送入每一类的svm分类器，判断是否属于该类
4. **位置精修：** 使用回归器精修候选框位置

####Fast R-CNN
与R-CNN区别：
1. **在特征提取阶段：** 是在R-CNN的基础上加入了感兴趣区域池化（ROI maxpooling），即将每个候选区域均匀分成m*n块，对每块进行max pooling。将特征图上大小不一的候选区域转变为大小统一的数据送入下一层。由于cnn网络的输入图像尺寸必须是某一固定大小，所以r-cnn对其进行了剪裁和缩放，这个过程花销过大。
2. **在分类回归阶段：** 在R-CNN中，先生成候选区域，然后通过cnn提取特征，然后通过svm进行分类，最后再做回归。而此网络则把回归也放入神经网络内部，与区域分类做了合并。

####Faster R-CNN
&emsp; 将候选区域的选择也交给一个提取边缘的神经网络，即区域生成网络（RPN），也就是说，从候选框的选取，到提取特征，分类，位置精修全部被统一到一个深度网络框架中。

![](https://raw.githubusercontent.com/nanfengchuiyeluo6/images/master/fasterRCNN.jpg)

&emsp; 上半部分是vgg16，用于提取特征形成feature map，从3*3卷积开始就是Region Proposal Networks（RPN）,两条线中，上面一条线是通过softmax分类anchor获得forground（前景）,一般检测的目标是foreground，下面一条线是用于计算anchors的bounding box regression偏移量，以获得精准的proposals。而最后的proposal层来综合前景和框偏移量来获取proposals，同时剔除不符合的proposals

####锚点（anchor）
&emsp; 简单来说，就是可以确定候选区域框的左上，右下的坐标点。这些候选框有三种面积：128，256，512。三种比例：1:1，1:2，2:1
![](https://raw.githubusercontent.com/nanfengchuiyeluo6/images/master/锚点.jpg)

&emsp; 如上图所示，经过卷积后形成的feture map，每个点都可能有k个anchor（即每个点都可能有k个以此点为中心的矩形框），在这些矩形框中，每个框都要分foreground和background，所以每个点由feature map转化为2k scores，并且每个框都有x，y，w，h对应的4个偏移量，所以是4k coordinates

###目标检测发展
![](https://raw.githubusercontent.com/nanfengchuiyeluo6/images/master/目标检测发展1.jpg)

&emsp; 从传统的人工设计特征+浅层分类器的框架，到基于大数据和深度神经网络的端到端的物体检测框架

###为什么传统的计算机视觉必不可少
1. 深度学习需要海量的数据，来提取特征，而传统的计算机视觉完全透明，允许你更好的评估判断你的解决方案是否在训练环境之外依然有效。
2. 深度学习容易过拟合。
3. 传统计算机视觉有时更省力。例如，检查每个通过的传送带的罐子中是否有一个红勺子，你可以使用深度学习方法训练网络，也可以直接以红色为阈值的算法（将任何带有一定范围红色的像素都标记为白色，其它的像素都标记为黑色）
4. 传统计算机视觉会提升你的深度学习技巧。如卷积神经网络中的卷积实际上被广泛运用到图像处理技术。还有就是预处理。

####传统的目标检测算法
1. 检测窗口的选择：
   &emsp; 最简单的方式就是暴力搜索候选框，但是这种方式，计算量很大并且效率不高。
   &emsp; 然后发现，可以利用先验知识来筛除一部分候选框，如人脸肤色YCbCr空间（一种颜色空间，和RGB并列）符合紧凑高斯分布，因此可以去除较大部分的候选框。但是如果遇到黄色的桌子等和人脸肤色较像的目标则很可能误判。
   &emsp; 进一步提升精度衍生出了selective search或edgebox等候选区提取方法。基于颜色聚类，边缘聚类的方法，迅速把不是所需的区域剔除掉。
2. 特征的设计：
   &emsp; Haar由于提取速度快，能够表达物体多种边缘变化信息，并且可以利用积分图快速计算，得到广泛应用。
   &emsp; LBP更多的表达物体的纹理信息，对均匀变化的光照有很好的适应性。
   &emsp; HOG通过对物体边缘使用直方图统计来进行编码。

![](https://raw.githubusercontent.com/nanfengchuiyeluo6/images/master/传统目标检测.jpg)

第一个传统的目标检测方法是2001年Viola-Jones检测框架。VJ检测采用最简单的滑动窗口检测手段，之所以它能够实时，有三个关键要素：多尺度Haar特征的快速计算，有效的特征选择算法和多阶段处理策略。


